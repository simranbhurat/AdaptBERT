{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d40144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transformers is not preinstalled in google colab\n",
    "# !pip install transformers\n",
    "\n",
    "# weights and biases is not preinstalled in google colab\n",
    "# !pip install wandb -q\n",
    "\n",
    "# jupyter setup\n",
    "# % commands are \"jupyter notbook commands\" - %matplotlib inline allows for inline plotting\n",
    "%matplotlib inline\n",
    " \n",
    "# import modules\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "# import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397c6aa1-97a1-42fd-bd5a-e40fd874fb15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install wandb -qqq\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "046c4f51-7386-4095-a297-2070955d5910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('final_patent.csv.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7c876a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "parameter_dict = {\n",
    "    'huggingface_model': 'bert-base-uncased', \n",
    "    'epochs' : 4,\n",
    "    'batch_size': 5,\n",
    "    'dropout_finetune': 0.2,\n",
    "    'learning_rate_AdamW': 2e-5,\n",
    "    'metadata_embedding_size': 128,\n",
    "    'hidden_layer_size': 2048,\n",
    "    'seed': 101\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584763a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = f\"{parameter_dict['huggingface_model']}-with-metadata-2hidden_layers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55d8e0d-1b0e-4920-863d-40974db42cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:c21q45nb) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b7159f42db4ff9b1779ed5255fead5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.014 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.630895…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-base-uncased-with-metadata-2hidden_layers</strong> at: <a href='https://wandb.ai/simranthesis/SimranThesis/runs/c21q45nb' target=\"_blank\">https://wandb.ai/simranthesis/SimranThesis/runs/c21q45nb</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230529_102501-c21q45nb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:c21q45nb). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5ff62666c44c37bf52621d9dc82c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666944226793324, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/pfs/data5/home/ma/ma_ma/ma_ssureshb/wandb/run-20230529_102559-fr2ikatq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/simranthesis/SimranThesis/runs/fr2ikatq' target=\"_blank\">bert-base-uncased-with-metadata-2hidden_layers</a></strong> to <a href='https://wandb.ai/simranthesis/SimranThesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/simranthesis/SimranThesis' target=\"_blank\">https://wandb.ai/simranthesis/SimranThesis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/simranthesis/SimranThesis/runs/fr2ikatq' target=\"_blank\">https://wandb.ai/simranthesis/SimranThesis/runs/fr2ikatq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/simranthesis/SimranThesis/runs/fr2ikatq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1551458f5ac0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"SimranThesis\", name=model_name, config=parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b65888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google made 2 GPU available for this notebook.\n",
      "GPU type: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# Set up torch for colab\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda') # specify the GPU we want to use in torch\n",
    "  print('Google made {} GPU available for this notebook.'.format(torch.cuda.device_count()))\n",
    "  print('GPU type: {}'.format(torch.cuda.get_device_name()))\n",
    "else:\n",
    "  print('CPU must be used')\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a36126-d0f1-459a-bcd7-e83db8829b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# function to remove all digits from the abstract\n",
    "def clean_abstract(text):\n",
    "    return re.sub(r\"\\d\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d820d927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm_tmpdir/job_22283538/ipykernel_496846/1490893273.py:2: DtypeWarning: Columns (1,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sample_data_df = pd.read_csv('final_patent.csv')\n"
     ]
    }
   ],
   "source": [
    "# sample_data_df = pd.read_csv(path_to_input.format('sample_data.csv'))\n",
    "sample_data_df = pd.read_csv('final_patent.csv')\n",
    "sample_data_df = sample_data_df.dropna()\n",
    "sample_data_df = sample_data_df.reset_index(drop=True)\n",
    "possible_labels = sample_data_df['cpc_code'].unique()\n",
    "\n",
    "numerical_encoding_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    numerical_encoding_dict[possible_label] = index\n",
    "\n",
    "sample_data_df['cpc_class_numerical'] = sample_data_df['cpc_code'].replace(numerical_encoding_dict)\n",
    "\n",
    "sample_data_df['text'] = sample_data_df['patent_title'].astype(str) + ' ' + sample_data_df['patent_abstract'].astype(str)\n",
    "sample_data_df['text'] = sample_data_df['text'].apply(lambda x: x.lower())\n",
    "sample_data_df['text'] = sample_data_df['text'].apply(clean_abstract)\n",
    "\n",
    "# metadata: review year ids\n",
    "sample_data_df['year'] = pd.to_datetime(sample_data_df['patent_date']).dt.year\n",
    "year_dict = {k: k-sample_data_df['year'].min() for k in sample_data_df['year'].unique()}\n",
    "sample_data_df['year_ids'] = sample_data_df['year'].replace(year_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030b40d-34aa-4bf0-9712-74b8672def93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_data_df.reset_index(inplace = True)\n",
    "sample_data_df = sample_data_df[['patent_id', 'cpc_code', 'cpc_class_numerical', 'text', 'year', 'year_ids']]\n",
    "# sample_data_df = sample_data_df_1\n",
    "sample_data_df_1 = sample_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ff667-bc72-4ba2-8eca-7e098a359eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_id</th>\n",
       "      <th>cpc_code</th>\n",
       "      <th>cpc_class_numerical</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>year_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000000</td>\n",
       "      <td>G01</td>\n",
       "      <td>0</td>\n",
       "      <td>coherent ladar using intra-pixel quadrature de...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000001</td>\n",
       "      <td>B29</td>\n",
       "      <td>1</td>\n",
       "      <td>injection molding machine and mold thickness c...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000002</td>\n",
       "      <td>B29</td>\n",
       "      <td>1</td>\n",
       "      <td>method for manufacturing polymer film and co-e...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000003</td>\n",
       "      <td>B29</td>\n",
       "      <td>1</td>\n",
       "      <td>method for producing a container from a thermo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000004</td>\n",
       "      <td>B29</td>\n",
       "      <td>1</td>\n",
       "      <td>process of obtaining a double-oriented film, c...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167318</th>\n",
       "      <td>9982317</td>\n",
       "      <td>C13</td>\n",
       "      <td>115</td>\n",
       "      <td>systems and methods for acid recycle methods a...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167319</th>\n",
       "      <td>9982386</td>\n",
       "      <td>D07</td>\n",
       "      <td>118</td>\n",
       "      <td>rope structure with improved bending fatigue a...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167320</th>\n",
       "      <td>9994924</td>\n",
       "      <td>C13</td>\n",
       "      <td>115</td>\n",
       "      <td>method for the fractionation of lignocellulosi...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167321</th>\n",
       "      <td>9994994</td>\n",
       "      <td>D07</td>\n",
       "      <td>118</td>\n",
       "      <td>hybrid rope hybrid rope () comprising a core e...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167322</th>\n",
       "      <td>9994995</td>\n",
       "      <td>D07</td>\n",
       "      <td>118</td>\n",
       "      <td>steel cord and method of manufacturing rubber ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167323 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       patent_id cpc_code  cpc_class_numerical  \\\n",
       "0       10000000      G01                    0   \n",
       "1       10000001      B29                    1   \n",
       "2       10000002      B29                    1   \n",
       "3       10000003      B29                    1   \n",
       "4       10000004      B29                    1   \n",
       "...          ...      ...                  ...   \n",
       "167318   9982317      C13                  115   \n",
       "167319   9982386      D07                  118   \n",
       "167320   9994924      C13                  115   \n",
       "167321   9994994      D07                  118   \n",
       "167322   9994995      D07                  118   \n",
       "\n",
       "                                                     text  year  year_ids  \n",
       "0       coherent ladar using intra-pixel quadrature de...  2018        42  \n",
       "1       injection molding machine and mold thickness c...  2018        42  \n",
       "2       method for manufacturing polymer film and co-e...  2018        42  \n",
       "3       method for producing a container from a thermo...  2018        42  \n",
       "4       process of obtaining a double-oriented film, c...  2018        42  \n",
       "...                                                   ...   ...       ...  \n",
       "167318  systems and methods for acid recycle methods a...  2018        42  \n",
       "167319  rope structure with improved bending fatigue a...  2018        42  \n",
       "167320  method for the fractionation of lignocellulosi...  2018        42  \n",
       "167321  hybrid rope hybrid rope () comprising a core e...  2018        42  \n",
       "167322  steel cord and method of manufacturing rubber ...  2018        42  \n",
       "\n",
       "[167323 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sample_data_df.groupby(['cpc_code', 'year']).head(30)\n",
    "sample_data_df = result.reset_index(drop=True)\n",
    "sample_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac79f4-7843-41ec-818a-21761d3e4c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming sample_data_df is your dataframe containing the 'text' column\n",
    "\n",
    "token_lengths = sample_data_df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "sns.histplot(token_lengths, kde=True)\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Token Length in Text Column')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bddc416-2765-4075-bdd5-b5043c0b4b1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Token Length: 118.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming sample_data_df is your dataframe containing the 'text' column\n",
    "\n",
    "median_token_length = sample_data_df['text'].str.split().apply(lambda x: len(x)).median()\n",
    "\n",
    "print(\"Median Token Length:\", median_token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed144ab-82c4-4bc7-b288-b830adef8774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm_tmpdir/job_22283538/ipykernel_496846/3984927391.py:14: FutureWarning: In a future version of pandas all arguments of StringMethods.rsplit except for the argument 'pat' will be keyword-only.\n",
      "  rd['text_all'] = rd['text_all'].str.rsplit('.', 1).str[0]\n"
     ]
    }
   ],
   "source": [
    "rd = pd.read_csv(\"abstract_title_text_RD.csv\")\n",
    "rd = rd[rd['language'] == 'en']\n",
    "\n",
    "rd = rd.dropna()\n",
    "rd = rd.reset_index(drop=True)\n",
    "\n",
    "# metadata: review year ids\n",
    "rd['year'] = pd.to_datetime(rd['date']).dt.year\n",
    "year_dict = {k: k-rd['year'].min() for k in rd['year'].unique()}\n",
    "rd['year_ids'] = rd['year'].replace(year_dict)\n",
    "\n",
    "rd['text_all'] = rd['abstract'].apply(lambda x: x.lower())\n",
    "rd['text_all'] = rd['text_all'].apply(clean_abstract)\n",
    "rd['text_all'] = rd['text_all'].str.rsplit('.', 1).str[0]\n",
    "\n",
    "# test_data = rd\n",
    "\n",
    "rd = rd.dropna()\n",
    "rd = rd.sample(frac=6, replace=True)\n",
    "rd = rd.reset_index(drop=True)\n",
    "\n",
    "rd = rd.iloc[:sample_data_df.shape[0]]\n",
    "\n",
    "# tranform data to lists\n",
    "feature_text_distance, feature_year_distance = rd['text_all'].to_list(), rd['year_ids'].to_list()\n",
    "# feature_text_target, feature_year_target = test_data['text_all'].to_list(), test_data['year_ids'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07e14e-92fc-4bcf-9932-dcb49dc48812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167323, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b06fa9c-137b-46fd-a798-31a4988ef315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167323, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassificationMetadata(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, config, num_year_ids, metadata_embedding_size, hidden_layer_size, dropout_fine_tune):\n",
    "        super().__init__(config)\n",
    "        self.bert = transformers.BertModel(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_fine_tune)\n",
    "        self.embedding_year = nn.Embedding(num_year_ids, metadata_embedding_size) #32, 128       \n",
    "        self.layer_normalizer = nn.LayerNorm(768 + metadata_embedding_size) # 896\n",
    "        self.fc1_hidden = nn.Linear(768 + metadata_embedding_size, hidden_layer_size)#896 , 2048\n",
    "        self.fc2_hidden = nn.Linear(hidden_layer_size, hidden_layer_size)#2048 , 2048\n",
    "        self.fc_classifier = nn.Linear(hidden_layer_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        year_ids: Optional[torch.Tensor] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], transformers.modeling_outputs.SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        year_embedding = self.embedding_year(year_ids)\n",
    "\n",
    "        pooled_bert_output = outputs[1]\n",
    "        \n",
    "        # print(pooled_bert_output.size(), year_embedding.size())\n",
    "        \n",
    "        # concat\n",
    "        input_classification_head = torch.cat((pooled_bert_output, year_embedding), dim=1)#32, 1024\n",
    "\n",
    "        # fc1\n",
    "        input_fc1_hidden = self.dropout(self.layer_normalizer(input_classification_head))#32, 1024\n",
    "        output_fc1_hidden = self.fc1_hidden(input_fc1_hidden)# 32, 768\n",
    "\n",
    "        # fc2\n",
    "        input_fc2_hidden = torch.relu(self.dropout(output_fc1_hidden))\n",
    "        output_fc2_hidden = self.fc2_hidden(input_fc2_hidden) #32, 768\n",
    "\n",
    "        # logit classifier\n",
    "        input_fc_classifier = torch.relu(self.dropout(output_fc2_hidden))\n",
    "        logits = self.fc_classifier(input_fc_classifier)\n",
    "\n",
    "        # loss\n",
    "        # loss_fct = nn.CrossEntropyLoss()\n",
    "        # loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        # loss\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        else:\n",
    "            loss = None\n",
    "            \n",
    "        return transformers.modeling_outputs.SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation test hold out split\n",
    "# test size\n",
    "test_size = 0.2\n",
    "\n",
    "# validation size\n",
    "val_size = 0.2\n",
    "\n",
    "# training size\n",
    "train_size = 0.6\n",
    "\n",
    "training_data, test_data = sklearn.model_selection.train_test_split(sample_data_df, test_size=test_size, random_state=parameter_dict['seed'])\n",
    "training_data, validation_data = sklearn.model_selection.train_test_split(training_data, test_size=val_size/(1-test_size), random_state=parameter_dict['seed'])\n",
    "# del all_data_df\n",
    "# tranform data to lists\n",
    "feature_text_train, feature_year_train, labels_train = training_data['text'].to_list(), training_data['year_ids'].to_list(), training_data['cpc_class_numerical'].to_list()\n",
    "feature_text_validation, feature_year_validation, labels_validation = validation_data['text'].to_list(), validation_data['year_ids'].to_list(), validation_data['cpc_class_numerical'].to_list()\n",
    "feature_text_test, feature_year_test, labels_test = test_data['text'].to_list(), test_data['year_ids'].to_list(), test_data['cpc_class_numerical'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f74cd8c9-7dd1-4bb4-b43e-3d602045c378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "median_token_length = int(median_token_length)\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "def fast_encode(texts, tokenizer, chunk_size=512, maxlen=400):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), chunk_size)):\n",
    "        text_chunk = texts[i:i + chunk_size]\n",
    "        encs = tokenizer.batch_encode_plus(\n",
    "            text_chunk,\n",
    "            max_length=maxlen,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )        \n",
    "        input_ids.append(encs['input_ids'])\n",
    "        attention_mask.append(encs['attention_mask'])\n",
    "\n",
    "    return {\n",
    "        'input_ids': torch.cat(input_ids, dim=0).squeeze(),\n",
    "        'attention_mask': torch.cat(attention_mask, dim=0).squeeze()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7532b09-86f1-4d72-968e-21cb3ae9808c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [03:47<00:00,  1.16s/it]\n",
      "100%|██████████| 66/66 [01:16<00:00,  1.16s/it]\n",
      "100%|██████████| 66/66 [01:17<00:00,  1.17s/it]\n",
      "100%|██████████| 327/327 [07:41<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "feature_text_train = fast_encode(feature_text_train, tokenizer)\n",
    "feature_text_validation = fast_encode(feature_text_validation, tokenizer)\n",
    "feature_text_test = fast_encode(feature_text_test, tokenizer)\n",
    "feature_text_target = fast_encode(feature_text_distance, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6d9ce31-8d49-4d79-8fce-a16c483f3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save the variables\n",
    "# with open('tokens_150.pickle', 'wb') as f:\n",
    "#     pickle.dump((feature_text_train, feature_text_validation, feature_text_test, feature_text_target), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb32f3a5-2208-4676-97e8-1cbcb952da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Restore the variables\n",
    "# with open('tokens_150.pickle', 'rb') as f:\n",
    "#     feature_text_train, feature_text_validation, feature_text_test, feature_text_target = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5945ef3b-8de1-466a-a1af-543d63bbda90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100393"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6db8c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup the pre-treained BERT Tokenizer\n",
    "# bert_tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# # Apply the tokenizer to the datasets\n",
    "# feature_text_train = bert_tokenizer(feature_text_train, padding='max_length', max_length=median_token_length, truncation =True, return_tensors='pt')\n",
    "# feature_text_validation = bert_tokenizer(feature_text_validation, padding='max_length', max_length=median_token_length, truncation =True, return_tensors='pt')\n",
    "# feature_text_test = bert_tokenizer(feature_text_test, padding='max_length', max_length=median_token_length, truncation =True, return_tensors='pt')\n",
    "# feature_text_target = bert_tokenizer(feature_text_distance, padding='max_length', max_length=median_token_length, truncation =True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99ae74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader for transformers\n",
    "class AttributeDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, tokenized_text: torch.Tensor, year_ids, labels):\n",
    "    self.tokenized_features = tokenized_text\n",
    "    self.year_ids = torch.tensor(year_ids)\n",
    "    self.labels = torch.tensor(labels)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: val[idx] for key, val in self.tokenized_features.items()}\n",
    "    item['year_ids'] = self.year_ids[idx]\n",
    "    item['labels'] = self.labels[idx]\n",
    "    return item\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "train_torch = AttributeDataset(feature_text_train, feature_year_train, labels_train)\n",
    "validation_torch = AttributeDataset(feature_text_validation, feature_year_validation, labels_validation)\n",
    "test_torch = AttributeDataset(feature_text_test, feature_year_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "821fa9a7-907f-4f3b-b96b-1edcdec3736d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the pre-treained BERT Tokenizer\n",
    "# bert_tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# data loader for transformers\n",
    "class AttributeDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, tokenized_text: torch.Tensor, year_ids):\n",
    "    self.tokenized_features = tokenized_text\n",
    "    self.year_ids = torch.tensor(year_ids)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: val[idx] for key, val in self.tokenized_features.items()}\n",
    "    item['year_ids'] = self.year_ids[idx]\n",
    "    return item\n",
    "\n",
    "  def __len__(self):\n",
    "    return rd.shape[0]\n",
    "\n",
    "target_torch = AttributeDataset(feature_text_target, feature_year_distance)\n",
    "target_dataloader = torch.utils.data.DataLoader(target_torch, batch_size=parameter_dict['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04f72687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassificationMetadata: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassificationMetadata from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassificationMetadata from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassificationMetadata were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['fc1_hidden.bias', 'fc_classifier.weight', 'fc1_hidden.weight', 'fc2_hidden.bias', 'layer_normalizer.weight', 'embedding_year.weight', 'fc_classifier.bias', 'layer_normalizer.bias', 'fc2_hidden.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 20079\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained BERT model and push it to the GPU memory\n",
    "\n",
    "#bert_classification_model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(numerical_encoding_dict))\n",
    "bert_classification_model = BertClassificationMetadata.from_pretrained('bert-base-uncased', num_labels=len(numerical_encoding_dict), num_year_ids = max(year_dict.keys()), metadata_embedding_size=parameter_dict['metadata_embedding_size'], hidden_layer_size=parameter_dict['hidden_layer_size'], dropout_fine_tune=parameter_dict['dropout_finetune'])\n",
    "\n",
    "# model to GPU\n",
    "bert_classification_model.to(device)\n",
    "\n",
    "# Define the data loader for batching, batch size 16 seems to work well\n",
    "# (higher would cause memory overflow problems on the GPU)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_torch, batch_size=parameter_dict['batch_size'], shuffle=True)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_torch, batch_size=parameter_dict['batch_size'], shuffle=True)\n",
    "number_of_batches = len(train_data_loader)\n",
    "print(f'Number of Batches: {number_of_batches}')\n",
    "\n",
    "# Setup the ADAM optimizer with generic parameters.\n",
    "optimizer = torch.optim.AdamW(bert_classification_model.parameters(), lr=parameter_dict['learning_rate_AdamW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5fa0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# milestones\n",
    "def training_milestone(number_of_milestones, number_of_batches):\n",
    "  batches_per_milestone = (number_of_batches-1)/number_of_milestones\n",
    "  milestone_list = [int(x*batches_per_milestone) for x in range(1, number_of_milestones)]\n",
    "  milestone_list.append(number_of_batches-1)\n",
    "  return milestone_list\n",
    "\n",
    "training_milestones = training_milestone(16, number_of_batches)\n",
    "\n",
    "# validation\n",
    "validation_milestones = training_milestone(4, number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dab64822-8c32-46ac-9f73-afe37be6ad3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mmd_loss(hidden_states_source, hidden_states_target, sigma):\n",
    "    # Compute the mean embeddings of the source and target domains\n",
    "    mean_source = torch.mean(hidden_states_source, dim=0)\n",
    "    mean_target = torch.mean(hidden_states_target, dim=0)\n",
    "\n",
    "    # Compute the MMD between the source and target domains\n",
    "    mmd = 0\n",
    "    for i in range(hidden_states_source.shape[0]):\n",
    "        for j in range(hidden_states_target.shape[0]):\n",
    "            dist = torch.sum(torch.square(hidden_states_source[i] - hidden_states_target[j]))\n",
    "            mmd += torch.exp(-dist / (2 * sigma ** 2))\n",
    "\n",
    "    return mmd / (hidden_states_source.shape[0] * hidden_states_target.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd8739f9-5381-4415-b906-361e1409ecbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100393"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14dd60a6-cfb5-49ff-8ab5-aca51ed8150a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33465"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff396bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Start Training -------------------------\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "start_time = time.time()\n",
    "# initialize training\n",
    "bert_classification_model.train()\n",
    "# first loss to high values to not save model\n",
    "sum_of_val_loss_min = 9999\n",
    "# iterator for the number of validation runs\n",
    "val_run_iter = 0\n",
    "\n",
    "print(''.join([25*'-', ' Start Training ', 25*'-']))\n",
    "print(''.join([25*'-', '----------------', 25*'-']))\n",
    "alpha = 0.01\n",
    "sigma = 1.0\n",
    "for epoch in range(parameter_dict['epochs']):\n",
    "    for batch_iter, (batch_source, batch_target) in enumerate(zip(train_data_loader, target_dataloader)):\n",
    "        # batch to GPU\n",
    "        # text\n",
    "        input_ids_source, attention_mask_source, year_ids_source, labels_source = batch_source['input_ids'].to(device), batch_source['attention_mask'].to(device), batch_source['year_ids'].to(device), batch_source['labels'].to(device)\n",
    "        input_ids_target, attention_mask_target, year_ids_target = batch_target['input_ids'].to(device), batch_target['attention_mask'].to(device), batch_target['year_ids'].to(device)\n",
    "        # after each updateing set optimzer gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs_source = bert_classification_model(input_ids=input_ids_source, attention_mask=attention_mask_source, year_ids=year_ids_source, labels = labels_source)\n",
    "        outputs_target = bert_classification_model(input_ids=input_ids_target, attention_mask=attention_mask_target, year_ids=year_ids_target)\n",
    "        hidden_states_target = outputs_target.hidden_states[0]\n",
    "        hidden_states_source = outputs_source.hidden_states[0]\n",
    "        \n",
    "        mmd_loss_value = mmd_loss(hidden_states_source, hidden_states_target, sigma)\n",
    "        # Compute the distance between the source and target distributions\n",
    "        target_dist = torch.mean(torch.exp(hidden_states_target), dim=0)\n",
    "        source_dist = torch.mean(torch.exp(hidden_states_source), dim=0)\n",
    "        \n",
    "        \"\"\"\n",
    "        the code computes the source and target distributions by taking the mean of the exponential values of the hidden states. \n",
    "        The exponential function is used to convert the hidden states into a probability distribution over the vocabulary.\n",
    "        The mean is computed along the batch dimension, resulting in a single probability distribution for each domain.\n",
    "        \"\"\"\n",
    "        distance = torch.sum(torch.abs(source_dist - target_dist))\n",
    "        \"\"\"\n",
    "        Finally, the code computes the distance between the source and target distributions using the L1 distance. \n",
    "        The L1 distance is the sum of the absolute differences between the corresponding elements of the two distributions. \n",
    "        This distance is used as a measure of how different the two domains are from each other. \n",
    "        The goal of domain adaptation is to minimize this distance, typically by adjusting the model's parameters to make it more robust to domain shift.\n",
    "        \"\"\"\n",
    "\n",
    "        # total_loss = outputs_source[0] + alpha * distance\n",
    "        \n",
    "        \"\"\"\n",
    "        The MMD loss measures the difference between the source and target domains in terms of their embeddings in a high-dimensional space defined by the Gaussian kernel.\n",
    "        The goal of the loss is to minimize this difference, which encourages the model to learn embeddings that are similar across domains.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute the total loss as a linear combination of the CE and MMD losses\n",
    "        loss = outputs_source[0] + alpha * mmd_loss_value\n",
    "        # backpropergation\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        # foward_pass_output['logits'] logits is the classifcation output\n",
    "        # before the softmax is applied --> the prediction is always the highest\n",
    "        # one.\n",
    "\n",
    "        # logging\n",
    "        training_log_dict = {\n",
    "            'training_loss': torch.mean(loss)\n",
    "            }\n",
    "\n",
    "        \n",
    "    # progress reporting \n",
    "    if batch_iter in training_milestones:\n",
    "      # save memory by not calculating a gradient\n",
    "      with torch.no_grad():\n",
    "        print(f'Epoch: {epoch}\\tBatch: {batch_iter}\\tTrain-Loss: {torch.mean(loss)}')\n",
    "    \n",
    "    # Validation:\n",
    "    # For each epoch I evaluate the model on a validation set twice. The model with \n",
    "    # the lowest (batch-wise sum) cross-entropy loss on the validation set is chosen.\n",
    "\n",
    "\n",
    "    if batch_iter in validation_milestones:\n",
    "      # set to evaluation (stop dropout)\n",
    "      bert_classification_model.eval()\n",
    "      print(''.join([25*'-', '----------------', 25*'-']))\n",
    "      print(f'Validation Run {val_run_iter} (Epoch {epoch}):')\n",
    "\n",
    "      # initaile selection cretarion.\n",
    "      sum_of_val_loss = 0\n",
    "      num_of_correct_predictions = 0\n",
    "      # loop over validation loss\n",
    "      for val_batch in validation_data_loader:\n",
    "        # permit pytroch to save gradients for the validation data since no \n",
    "        # backpropergation is not needed (save memory)\n",
    "\n",
    "        with torch.no_grad():\n",
    "         \n",
    "          # batch to GPU\n",
    "          # text\n",
    "          batch_text_inputids = val_batch['input_ids'].to(device)\n",
    "          batch_text_attention_mask = val_batch['attention_mask'].to(device)\n",
    "\n",
    "          # metadata\n",
    "          batch_yearids = val_batch['year_ids'].to(device)\n",
    "\n",
    "          #labels\n",
    "          labels = val_batch['labels'].to(device)\n",
    "    \n",
    "          # forward pass\n",
    "          forward_pass_output = bert_classification_model(input_ids=batch_text_inputids, attention_mask=batch_text_attention_mask, year_ids=batch_yearids, labels=labels)\n",
    "          loss = forward_pass_output[0]\n",
    "\n",
    "          # add batch specific loss\n",
    "          sum_of_val_loss += loss\n",
    "\n",
    "          # accuracy\n",
    "          num_of_correct_predictions += torch.sum(forward_pass_output['logits'].argmax(axis=1) == labels)\n",
    "\n",
    "      # log the loss and precision of the model\n",
    "\n",
    "      mean_loss_val = sum_of_val_loss/len(validation_data)\n",
    "      accuracy_val = num_of_correct_predictions/len(validation_data)\n",
    "      validation_log_dict = {\n",
    "          'validation_loss': sum_of_val_loss/len(validation_data),\n",
    "          'validation_accuracy': num_of_correct_predictions/len(validation_data)\n",
    "        }\n",
    "\n",
    "      # print validation results\n",
    "      print(f'\\t{val_run_iter}\\n\\t Val-Loss: \\t{mean_loss_val}\\n\\t Val-Accu: \\t{accuracy_val}')\n",
    "\n",
    "      # update iter\n",
    "      val_run_iter += 1\n",
    "      # save the model if loss improved\n",
    "      if (sum_of_val_loss<sum_of_val_loss_min):\n",
    "        sum_of_val_loss_min = sum_of_val_loss\n",
    "        torch.save(bert_classification_model, f'{model_name}.pt')\n",
    "        print(''.join(['!'*25, ' New best Model ', '!'*25]))\n",
    "      \n",
    "      # print validation loss\n",
    "      print(''.join([25*'-', '----------------', 25*'-']))\n",
    "      print(f'Resume Training:')\n",
    "      # set to training (activate dropout)\n",
    "      bert_classification_model.train()\n",
    "        \n",
    "      # log validation\n",
    "      wandb.log(validation_log_dict)\n",
    "\n",
    "    # log training  \n",
    "    wandb.log(training_log_dict)\n",
    "\n",
    "# end training           \n",
    "bert_classification_model.eval() \n",
    "print('The Training took: ',time.time()-start_time, 'Seconds')\n",
    "# del bert_classification_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7845a-783c-4b87-9166-b9ddede7905b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(target_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c89017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the fine tuned model chosen on the validation set\n",
    "# classification_model = torch.load((f'{model_name}.pt'), map_location=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a1b04-3754-4bae-8afd-cd4e4a869c57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rd = pd.read_csv(\"abstract_title_text_RD.csv\")\n",
    "rd = rd[rd['language'] == 'en']\n",
    "\n",
    "rd = rd.dropna()\n",
    "rd = rd.reset_index(drop=True)\n",
    "\n",
    "# metadata: review year ids\n",
    "rd['year'] = pd.to_datetime(rd['date']).dt.year\n",
    "year_dict = {k: k-rd['year'].min() for k in rd['year'].unique()}\n",
    "rd['year_ids'] = rd['year'].replace(year_dict)\n",
    "\n",
    "rd['text_all'] = rd['abstract'].apply(lambda x: x.lower())\n",
    "rd['text_all'] = rd['text_all'].apply(clean_abstract)\n",
    "rd['text_all'] = rd['text_all'].str.rsplit('.', 1).str[0]\n",
    "\n",
    "# test_data = rd\n",
    "\n",
    "rd = rd.dropna()\n",
    "# rd = rd.sample(frac=10, replace=True)\n",
    "rd = rd.reset_index(drop=True)\n",
    "\n",
    "# tranform data to lists\n",
    "feature_text_target, feature_year_target = rd['text_all'].to_list(), rd['year_ids'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b2a66-a1ae-4533-999b-73f750225680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup the pre-treained BERT Tokenizer\n",
    "# bert_tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "feature_text_target = fast_encode(feature_text_target, tokenizer)\n",
    "# Apply the tokenizer to the datasets\n",
    "# feature_text_target= bert_tokenizer(feature_text_target, padding='max_length', max_length = median_token_length, truncation =True, return_tensors='pt')\n",
    "\n",
    "# data loader for transformers\n",
    "class AttributeDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, tokenized_text: torch.Tensor, year_ids):\n",
    "    self.tokenized_features = tokenized_text\n",
    "    self.year_ids = torch.tensor(year_ids)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: val[idx] for key, val in self.tokenized_features.items()}\n",
    "    item['year_ids'] = self.year_ids[idx]\n",
    "    return item\n",
    "\n",
    "  def __len__(self):\n",
    "    return rd.shape[0]\n",
    "\n",
    "target_torch = AttributeDataset(feature_text_target, feature_year_target)\n",
    "target_dataloader = torch.utils.data.DataLoader(target_torch, batch_size=parameter_dict['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ab4db-0f2b-4caf-8469-6367dd4f777e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ignore dropout for testing\n",
    "bert_classification_model.eval()\n",
    "\n",
    "# timer\n",
    "start_time = time.time()\n",
    "\n",
    "# load test data\n",
    "test_data_loader = torch.utils.data.DataLoader(test_torch, batch_size=parameter_dict['batch_size'])\n",
    "\n",
    "# numpy arrays to store predictions and true labels.\n",
    "predictions = np.array([])\n",
    "true_labels = np.array([])\n",
    "\n",
    "# train the model\n",
    "for test_batch in test_data_loader:\n",
    "\n",
    "    # I do not need gradient\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # batch to GPU\n",
    "        # text\n",
    "        batch_text_inputids = test_batch['input_ids'].to(device)\n",
    "        batch_text_attention_mask = test_batch['attention_mask'].to(device)\n",
    "\n",
    "        # metadata\n",
    "        batch_yearids = test_batch['year_ids'].to(device)\n",
    "\n",
    "        #labels\n",
    "        labels = test_batch['labels'].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        foward_pass_output = bert_classification_model(input_ids=batch_text_inputids, attention_mask=batch_text_attention_mask, year_ids=batch_yearids, labels=labels)\n",
    "        \n",
    "        # foward_pass_output['logits'] logits is the classifcation output\n",
    "        # before the softmax is applied --> the prediction is always the highest\n",
    "        # one.\n",
    "        predictions = np.append(predictions, foward_pass_output['logits'].argmax(axis=1).cpu().numpy())\n",
    "\n",
    "        # since I shuffle the batche\n",
    "        true_labels = np.append(true_labels, labels.cpu().numpy())\n",
    "\n",
    "print('Out-of-sample predictions took: ',time.time()-start_time, 'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b26db-84c7-4fbe-9c19-f50f58019ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecdb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluations\n",
    "import tables\n",
    "Path((f'{model_name}')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# tests\n",
    "test_statistic = dict()\n",
    "test_statistic['accuracy'] = sklearn.metrics.accuracy_score(true_labels, predictions)\n",
    "test_statistic['recall'] = sklearn.metrics.recall_score(true_labels, predictions, average='macro')\n",
    "test_statistic['precison'] = sklearn.metrics.precision_score(true_labels, predictions, average='macro')\n",
    "test_statistic['f1_score'] = sklearn.metrics.f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "# logging measures\n",
    "test_statistics_table = wandb.Table(columns=list(test_statistic.keys()), data=[list(test_statistic.values())])\n",
    "wandb.log({\"test_table\" : test_statistics_table})\n",
    "\n",
    "# # to df and safe\n",
    "scores_df = pd.DataFrame.from_dict(test_statistic, orient='index').reset_index().rename(columns={'index': 'measure', 0: 'score'})\n",
    "scores_df.to_csv((f'{model_name}/measures_{model_name}_test.csv'), index=False)\n",
    "print(f'Evaluation Measures Test Set:\\n{scores_df.to_markdown()}\\n')\n",
    "\n",
    "# logging confusion matrix\n",
    "wandb.log({\"confusion_matrix_test\" : wandb.plot.confusion_matrix(probs=None, y_true=true_labels, preds=predictions, class_names=list(numerical_encoding_dict.keys()))})\n",
    "\n",
    "# # get the confusion matrix\n",
    "# confusion_matrix = sklearn.metrics.confusion_matrix(true_labels, predictions)\n",
    "# confusion_matrix_plot = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix.astype('int'), display_labels=numerical_encoding_dict.keys())\n",
    "# confusion_matrix_plot.plot(values_format='.0f', xticks_rotation='vertical')\n",
    "# print('Confusion Matrix Test Set:')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig((f'{model_name}/confusion_matirx_{model_name}_test.png'), bbox_inches='tight', dpi=1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef606e59-51d3-4d5a-8bbb-d32a5b100505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore dropout for prediction\n",
    "bert_classification_model.eval()\n",
    "\n",
    "# timer\n",
    "start_time = time.time()\n",
    "\n",
    "# numpy arrays to store predictions and true labels.\n",
    "predictions = np.array([])\n",
    "true_labels = np.array([])\n",
    "\n",
    "# train the model\n",
    "for target_batch in target_dataloader:\n",
    "\n",
    "    # I do not need gradient\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # batch to GPU\n",
    "        # text\n",
    "        batch_text_inputids = target_batch['input_ids'].to(device)\n",
    "        batch_text_attention_mask = target_batch['attention_mask'].to(device)\n",
    "\n",
    "        # metadata\n",
    "        batch_yearids = target_batch['year_ids'].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        foward_pass_output = bert_classification_model(input_ids=batch_text_inputids, attention_mask=batch_text_attention_mask, year_ids=batch_yearids)\n",
    "        \n",
    "        # foward_pass_output['logits'] logits is the classifcation output\n",
    "        # before the softmax is applied --> the prediction is always the highest\n",
    "        # one.\n",
    "        predictions = np.append(predictions, foward_pass_output['logits'].argmax(axis=1).cpu().numpy())\n",
    "\n",
    "print('predictions took: ',time.time()-start_time, 'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions_400_tokens.txt', 'w') as file:\n",
    "    for item in predictions:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2440eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = list(map(int, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e98134",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_keys = []\n",
    "\n",
    "for prediction in predictions_list:\n",
    "    for key, value in numerical_encoding_dict.items():\n",
    "        if value == prediction:\n",
    "            matched_keys.append(key)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5af55-0c90-4d0a-9e34-5b6f16457880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(predictions_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9772b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd['Predicted_Label'] = matched_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_predicted = rd[['rdid', 'text_all', 'year', 'Predicted_Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_predicted.to_csv(\"rd_predicted_400.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744d6b2-bee3-4de8-a94a-695d127568e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rd_predicted.Predicted_Label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5d572-4f73-489f-a57f-30375a37e8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc650f-4e26-44db-89f2-19f7267c129a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3dfe8a-0137-413d-8c33-5c790069d562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784032e2-c97a-4892-a210-cb7af1c3f18b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
